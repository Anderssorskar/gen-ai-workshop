{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and activate a virtual environment (Optional)\n",
    "- `python -m venv openai-env`\n",
    "- `source openai-env/bin/activate` (Mac)\n",
    "- `openai-env\\Scripts\\activate` (Windows)\n",
    "\n",
    "Once the virtial environment is set up, install the OpenAI Python library:\n",
    "- `pip install --upgrade openai`\n",
    "\n",
    "or if you want to install additional libraries which could be useful, including langchain:\n",
    "- `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code is setting up three string constants:\n",
    "\n",
    "- OPENAI_API_KEY: This is the API key for OpenAI. It's used to authenticate your application when making requests to the OpenAI API.\n",
    "\n",
    "- EMBEDDING_MODEL: This is the name of the model used for text embedding. Text embedding is a way to convert text into a form that can be processed by machine learning algorithms. In this case, the model is \"text-embedding-ada-002\".\n",
    "\n",
    "- LLM: This is the name of the language model used by OpenAI. We recommend using `gpt-4o-mini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the available models you can choose to experiment with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4o',\n",
       " 'tts-1',\n",
       " 'tts-1-1106',\n",
       " 'chatgpt-4o-latest',\n",
       " 'gpt-4-turbo-preview',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-4o-realtime-preview-2024-10-01',\n",
       " 'dall-e-3',\n",
       " 'gpt-4o-realtime-preview',\n",
       " 'gpt-4o-2024-08-06',\n",
       " 'gpt-4o-mini',\n",
       " 'gpt-4o-mini-2024-07-18',\n",
       " 'tts-1-hd',\n",
       " 'text-embedding-ada-002',\n",
       " 'text-embedding-3-small',\n",
       " 'text-embedding-3-large',\n",
       " 'whisper-1']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.id for model in client.models.list().data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "LLM = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code uses the OpenAI API to create a chat completion. It's using the GPT-4 model to generate responses to a user's question about Telenor.\n",
    "\n",
    "Here's a breakdown of the code:\n",
    "\n",
    "- `client.chat.completions.create`: This is a method from the OpenAI API that creates a chat completion. A chat completion is a conversation with the model where you provide a series of messages and the model returns a generated message as a response.\n",
    "\n",
    "- `model=\"gpt-4o-mini\"`: This specifies the model to use for the chat completion.\n",
    "\n",
    "- `messages`: This is a list of messages to send to the model. Each message is a dictionary with two keys: 'role' and 'content'. 'role' can be 'system', 'user', or 'assistant', and 'content' is the text of the message. The 'system' role is used to set the behavior of the 'assistant', and the 'user' role is used to ask the assistant a question.\n",
    "\n",
    "In this example, the system message sets the assistant's role as a helpful assistant that can answer questions about Telenor. The user message then asks the question \"What does Telenor do?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Telenor er et ledende telekommunikasjonsselskap som tilbyr ulike tjenester innen mobil- og bredbåndskommunikasjon. Selskapet er aktivt i flere markeder, både i Norge og internasjonalt. Telenor driver med følgende hovedområder:\\n\\n1. **Mobiltelefonitjenester**: Telenor tilbyr mobilabonnementer, både for privatkunder og bedrifter, inkludert tale, tekstmeldinger og data.\\n\\n2. **Bredbåndstjenester**: De leverer fastlinje-bredbånd med forskjellige hastigheter, samt fiberoptiske tjenester.\\n\\n3. **TV-tjenester**: Telenor tilbyr TV-løsninger, inkludert IPTV og streaming-tjenester.\\n\\n4. **IoT (Internet of Things)**: Selskapet jobber med IoT-løsninger for å koble opp enheter og systemer, noe som er særlig relevant for smarte byer og industri.\\n\\n5. **Finansielle tjenester**: Telenor har også hatt fokus på mobile betalingsløsninger og finansielle tjenester i flere markeder, inkludert samarbeid med lokale aktører.\\n\\n6. **Bedriftstjenester**: De tilbyr en rekke kommunikasjonstjenester og løsninger for bedriftskunder, inkludert skyløsninger, sikkerhetstjenester og samarbeidsverktøy.\\n\\nTelenor er kjent for sitt engasjement i bærekraft og digital inkludering, hvor de arbeider for å redusere miljøpåvirkningen og bidra til at flere får tilgang til digitale tjenester.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=LLM,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Du er en hjelpsom assistent som kan svare på spørsmål om Telenor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hva driver Telenor med?\"}\n",
    "        ]\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code is using the OpenAI API to create an embedding for a given text input.\n",
    "\n",
    "Here's a breakdown of the code:\n",
    "\n",
    "- `client.embeddings.create()`: This is a method from the OpenAI API that creates an embedding. An embedding is a vector representation of the input text. It's a way of converting text into a form that can be processed by machine learning algorithms. It also enables you to perform vector search using e.g. cosine similarity. \n",
    "\n",
    "- `model=\"text-embedding-ada-002\"`: This specifies the model to use for creating the embedding. In this case, it's using the \"text-embedding-ada-002\" model.\n",
    "\n",
    "- `input=\"Verdifull informasjon om Telenor som du vil bruke inn i språkmodellen.\"`: This is the text input for which the embedding will be created.\n",
    "\n",
    "- `encoding_format=\"float\"`: This specifies the format of the encoding for the embedding. In this case, it's set to \"float\", which means the embedding will be a list of floating-point numbers.\n",
    "\n",
    "In this example, the code is creating an embedding for the text \"Verdifull informasjon om Telenor som du vil bruke inn i språkmodellen.\" using the \"text-embedding-ada-002\" model and a floating-point encoding format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model_name: str):\n",
    "    embedding = client.embeddings.create(\n",
    "        model=model_name,\n",
    "        input=text,\n",
    "        encoding_format=\"float\"\n",
    "    )\n",
    "    return embedding.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `cos_sim` is calculating the cosine similarity between two vectors `a` and `b`. If the vectors are identical, the cosine similarity is 1. If the vectors are orthogonal (i.e., not similar at all), the cosine similarity is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = [\n",
    "    \"Telia Norge er et ledende teknologiselskap som bygger samfunnskritisk infrastruktur og leverer innovative produkter og tjenester innen TV, internett, mobil og smart hjem-teknologi.\",\n",
    "    \"Telenor Norge er landets største digitale tjenesteleverandør innenfor mobil, bredbånd og TV-tjenester. Hver dag jobber vi for å lede an i digitaliseringen av Norge og utvikle de beste digitale sikkerhetstjenestene for våre kunder.\",\n",
    "    \"Eple er en frukt kjent allerede fra steinalderen og finnes i dag i et ukjent antall varianter.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Hva driver Telenor med?\"\n",
    "\n",
    "input_embedding = get_embedding(input_text, EMBEDDING_MODEL)\n",
    "example_embedding = [get_embedding(ex, EMBEDDING_MODEL) for ex in example_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity indicates semantic similarity between the user input message and the document(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8768048924494523, 0.8814451296547565, 0.7605974032552157]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores = [cos_sim(input_embedding, ex_embedding) for ex_embedding in example_embedding]\n",
    "similarity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API has a limit on the maximum number of input tokens for embeddings. The following function calculates number of tokens from a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to augment LLM with \"new\" knowledge: Retrieval augmented generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data_df = pd.DataFrame({\"content\": example_data})\n",
    "example_data_df[\"embedding\"] = example_data_df.apply(lambda x: get_embedding(x[\"content\"], EMBEDDING_MODEL), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = [cos_sim(input_embedding, ex_embedding) for ex_embedding in example_data_df['embedding']]\n",
    "max_index = np.argmax(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_relevant_data = example_data_df['content'][max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"Du er en hjelpsom assistent som kan svare på spørsmål om Telenor.\n",
    "                     Du skal basere svarene dine på følgende informasjon: {most_relevant_data}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=LLM,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": \"Hva driver Telenor med?\"}\n",
    "        ]\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
